<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Landing - Forty by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<!-- Note: The "styleN" class below should match that of the banner element. -->
					<header id="header" class="alt style2">
						<a href="index.html" class="logo"><strong>Forty</strong> <span>by HTML5 UP</span></a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="landing.html">Landing</a></li>
							<li><a href="reseach.html">Research</a></li>
							<li><a href="generic.html">Generic</a></li>
							<li><a href="elements.html">Elements</a></li>
						</ul>
						<ul class="actions stacked">
							<li><a href="#" class="button primary fit">Get Started</a></li>
							<li><a href="#" class="button fit">Log In</a></li>
						</ul>
					</nav>

				<!-- Banner -->
				<!-- Note: The "styleN" class below should match that of the header element. -->
					<section id="banner" class="style2">
						<div class="inner">
							<span class="image">
								<img src="images/pic07.jpg" alt="" />
							</span>
							<header class="major">
								<h1>Research Methods and Professional Practice July 2025 B</h1>
							</header>
							<div class="content">
								<p>
									
								</p>
								
							</div>
						</div>
					</section>

				<!-- Main -->
					<div id="main">

						<!-- Two -->
							<section id="two" class="spotlights">
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Unit 1</h3>
											</header>
											<p>
												<strong>What</strong><br>
												The rise of generative AI since late 2022 has been dramatic: systems capable of producing text, images, audio and video now permeate many domains, including computing, education, business and research. While the idea of AI isn’t new, the rapid scale, accessibility and general-purpose nature of today’s models mean we are facing a different set of rules and challenges. The readings for this unit (Kluge‑Corrêa et al., 2023; Deckard, 2023) focus on AI governance from a global perspective and the professional/ethical implications for computing practitioners. Kluge‑Corrêa et al. observe that although “a lot of work is taking place to define the values and ideas that should guide AI advances,” a key challenge is establishing consensus on those values given diverse stakeholder perspectives. Their meta-analysis of governance documents found common themes but also significant divergences across national, institutional and cultural boundaries.<br><br>

												Deckard (2023) addresses the role of computing professionals, ethics and codes of conduct in the age of AI, emphasising that ethics cannot be an afterthought: professional responsibility, accountability and transparency must be embedded in practice. In short, these readings set the scene: generative AI is disrupting the status quo, governance frameworks are struggling to keep up, and computing professionals must adapt to a new ethical, social and legal terrain.<br><br>

												<strong>So what</strong><br>
												Why does this matter for computing professionals and society? Several implications emerge. First, the lack of global consensus on AI values means systems developed in one context can carry assumptions that conflict elsewhere, causing legal, reputational and social risk. Second, generative AI blurs traditional boundaries of roles and responsibilities: when algorithmic systems act quasi‑autonomously the question “who is responsible?” becomes fuzzy, complicating liability, oversight and explainability. Third, the social dimension is substantial — bias, misinformation, labour disruption and environmental impact extend harms beyond direct users to communities and society. Fourth, legal and regulatory moves (AI laws, audits, transparency requirements) make compliance, auditability and governance operational necessities for practitioners.<br><br>

												<strong>Now what</strong><br>
												Given these reflections, here are practical steps for computing professionals, students and institutions:<br><br>
												1. Embed ethics and governance early — incorporate values, dataset transparency, human‑in‑the‑loop oversight and auditability from design onward. Adopt the strictest plausible standards where contexts vary.<br><br>
												2. Professional adaptation and certification — update professional identity beyond coding: internalise codes of conduct (BCS, ACM, etc.) and advocate for registered professionals in high‑stakes AI deployments.<br><br>
												3. Contextual governance and stakeholder engagement — involve users, affected communities and regulators; plan for cultural context and multi‑level governance frameworks.<br><br>
												4. Transparency, auditability and continuous monitoring — log, monitor and evaluate systems post‑deployment; provide redress mechanisms and prepare for regulatory audits.<br><br>
												5. Education and awareness — include ethical, legal and social issues (ELSI) in curricula and professional development; keep up to date with national AI acts and standards.<br><br>
												6. Balance innovation and caution — match innovation goals with safeguards, intended use cases and mitigation or rollback plans.<br><br>
												7. Prepare for legal and professional accountability — ensure documentation, traceability and clear human decision points; seek complementary study in AI law and policy.<br><br>

												<strong>Conclusion</strong><br>
												Unit 1 underscores that generative AI is a paradigm shift for computing professionals. The “What” describes the evolving technology and governance landscape; the “So What” explains why this matters; and the “Now What” outlines concrete actions practitioners and institutions should take to steward AI responsibly. Ignoring these issues risks bias, loss of trust and legal or reputational fallout. Proactive governance, ethical reflection and transparency can help steer generative AI toward beneficial outcomes.<br><br>
												<strong>References</strong><br>
												Kluge‑Corrêa, N., et al. (2023). A review of 200 guidelines and recommendations for AI governance. Information, Communication & Society. doi:10.xxxx.<br>
												Deckard, R. (2023). What are ethics in AI? BCS Article.<br>
												(Additional references consulted: Pant et al., 2023; Budhwar et al., 2023.)<br><br>
												</p>
											</div>
										</div>
									</section>
									<section>
										<div class="content">
											<div class="inner">
												<header class="major">
													<h3>Unit 2</h3>
												</header>
												<p>
												<strong>What</strong><br>
												My chosen topic, "Cloud computing for building effective information systems in the banking sector," directly relates to my professional environment, where my organisation is transitioning from legacy datacentres to cloud infrastructure as part of a cloud-first strategy. This shift aims to improve scalability, agility, and resilience across critical banking systems. The migration involves not only technical transformation but also changes to governance, data management, and security frameworks. Cloud adoption promises to modernise our information systems and enable real-time analytics, yet it also presents challenges in regulatory compliance, data sovereignty, and operational risk.<br><br>

												<strong>So What</strong><br>
												Reflecting on this transformation, I recognise how cloud computing is reshaping the very foundation of information systems in banking. It enables integration across platforms, supports advanced analytics, and reduces infrastructure costs, aligning with business agility goals (Marinescu, 2023). However, it also magnifies issues around confidentiality, integrity, and availability of data, all of which are central to the financial sector's trust model (Alshamaila et al., 2021). For internal auditors and technology leaders, the shift demands new competencies: understanding shared-responsibility models, re-evaluating control frameworks, and aligning cloud practices with financial regulations such as the FCA and PRA operational resilience requirements. Personally, this reflection has helped me appreciate that technical migration alone is insufficient - cultural change, skill development, and risk governance must progress in parallel.<br><br>

												<strong>Now What</strong><br>
												Moving forward, I plan to deepen my technical and governance expertise in cloud security and regulatory compliance to support the organisation's strategic goals. Professionally, this means engaging with the audit and engineering teams to embed robust control testing in the cloud environment and ensuring that resilience and data protection principles are maintained – I have added an audit to this year's plan to deep into good practices in cloud environments using CIS benchmarks. Academically, I intend to explore comparative studies on hybrid versus multi-cloud adoption in finance to identify best practices for risk mitigation and operational efficiency. More broadly, I see the cloud-first journey as an opportunity for the banking industry to redefine what "effective" information systems mean. not just efficient or scalable, but secure, transparent, and compliant by design. Also, please refer to Unit 7 for the article submitted on building effective cloud environments, namely: "Cloud Computing for Building Effective Information Systems in Banking: A Standalone Literature Review".<br><br>

												<strong>References</strong><br>
												Alshamaila, Y., Papagiannidis, S. and Li, F. (2021) 'Cloud computing adoption by SMEs in the UK: A multi-perspective framework', Information Systems Frontiers, 23(2), pp. 389–406.<br>
												Marinescu, D. C. (2023) Cloud computing: Theory and practice. 3rd edn. London: Elsevier.<br>
												</p>
											</div>
										</div>
									</section>
									<section>
										<div class="content">
											<div class="inner">
												<header class="major">
													<h3>Uni 3</h3>
												</header>
												<p>
												<strong>Reflection Summary</strong><br>
												My aim is to assess whether LLM-assisted coding increases or decreases software vulnerabilities, fits within conclusive research, specifically a descriptive–causal design. The aim is to verify measurable effects rather than explore an undefined problem. An experimental method was chosen because it allows variable control and statistical testing to determine causal relationships.<br><br>
												Data is collected through static analysis tools (e.g., Semgrep, CodeQL, Bandit) and manual code reviews, ensuring both precision and reliability. This mixed approach links quantitative rigour with human validation.<br><br>
												To execute this, I need strong skills in software security, experimental design, and statistical modelling, as well as the ability to interpret results and manage ethical research processes. Going forward, I plan to develop deeper expertise in data analysis, SAST tools, and governance implications to strengthen both my project and my professional capability in evidence-based cybersecurity auditing.<br><br>							
												</p>
										</div>
									</div>
								</section>
								<section>								
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Unit 4</h3>
											</header>
											<p>
												<strong>What</strong><br>
												In Unit 4, I explored key qualitative data collection methods—case studies, focus groups, and observation (both qualitative and quantitative). Each provides different insights depending on the research aim. Case studies offer depth and help generate hypotheses but lack generalisability. Focus groups encourage discussion and can reveal motivations behind behaviour, while observational methods provide naturalistic data that capture real-world actions and contexts.<br><br>

												<strong>So What</strong><br>
												Reflecting on my upcoming project on AI-assisted code security, these methods can complement the experimental and quantitative design. For instance, conducting focus groups or interviews with developers could uncover perceptions of LLM reliability, prompting improvements in experimental task design. Meanwhile, quantitative observation, such as measuring coding performance metrics, aligns directly with my current methodology. Understanding these qualitative techniques helps me recognise that numerical data alone may not capture the full context of developer behaviour or ethical considerations.<br><br>

												<strong>Now What</strong><br>
												Going forward, I plan to integrate qualitative insights (where possible) into future research phases by gathering participant feedback on usability and trust in AI tools. To do this effectively, I will develop stronger skills in facilitating focus groups, designing semi-structured questions, and analysing qualitative data (e.g., thematic coding). Combining observational and quantitative evidence will make my findings more holistic, linking human experience with measurable technical outcomes.<br><br>
				
											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Unit 5</h3>
											</header>
											<p>
												<strong>What</strong><br>
												In 2018, Cambridge Analytica was exposed for harvesting personal data from more than 80 million Facebook users via an apparently harmless personality quiz app, “This Is Your Digital Life” (Confessore, 2018). Although only 270,000 people completed the survey, the app exploited Facebook’s API to extract data from participants’ friends without consent. The company then used this information to construct psychographic profiles for political micro-targeting during the 2016 US election and the UK Brexit campaign.<br><br>
												Similar misuse has appeared elsewhere:<br><br>
												•	In 2020, some health-tracking surveys distributed through social-media ads were found to collect location and demographic data for commercial resale rather than public-health analysis (Vincent, 2020).<br><br>
												•	The TikTok “personality quiz” scams of 2023 gathered email addresses and interests for phishing and influencer-marketing databases (BBC News, 2023).<br><br>
												Each instance weaponised voluntary participation to extract data for undeclared purposes, breaching both user trust and privacy law.<br><br>
												<strong>So What</strong><br>
												From an ethical perspective, these cases represent a failure of informed consent and data minimisation, which are core principles in information ethics and professional conduct. Participants were deceived about the intent of data collection, violating respect for autonomy and transparency.<br><br>
												Socially, the misuse of survey data undermines public confidence in online research and contributes to polarisation by enabling psychological manipulation in political discourse.<br><br>
												From a legal standpoint, such practices contravene provisions of the UK Data Protection Act 2018 and GDPR, which mandate lawful, fair, and transparent processing of personal data. In the US, although federal privacy law is weaker, the Federal Trade Commission later sanctioned similar behaviour as “unfair and deceptive.”<br><br>
												Professionally, the BCS Code of Conduct (BCS, 2023) obliges computing practitioners to respect privacy, uphold integrity, and avoid misuse of personal information. The Cambridge Analytica incident exposed systemic negligence—developers who built or maintained the survey infrastructure failed to enforce data-handling safeguards, while executives exploited the resulting data for profit and influence.<br><br>
												The correlates with my AI-security research in Unit 10 given both illustrate that technical capability without ethical guardrails leads to exploitation. Whether generating code or collecting survey data, the underlying risk is the same: unchecked automation and data access magnify harm when ethical governance lags behind innovation.<br><br>

												<strong>Now What</strong><br>
												For professionals, several corrective actions emerge:<br><br>
												1.	Ethical design and transparency – Surveys and digital tools must declare data-use purposes clearly, provide granular consent options, and prevent secondary use without explicit permission.<br><br>
												2.	Data-protection-by-design – Implement privacy-preserving architectures (e.g., differential privacy, anonymisation) and strict API-access limits.<br><br>
												3.	Regulatory alignment and auditability – Organisations should embed GDPR compliance checks and independent data-ethics audits in product lifecycles.<br><br>
												4.	Professional accountability – Developers, data scientists, and auditors should follow codes such as the BCS and ACM guidelines to ensure ethical integrity.<br><br>
												5.	Public education – Raising user awareness about data-sharing risks can mitigate manipulation through deceptive surveys.<br><br>

												By integrating these measures, computing professionals can uphold the same security and ethical discipline advocated in AI-assisted development - safeguarding users not merely through compliance, but through conscientious professional judgement.<br><br>

												<strong>References</strong><br>
												Vincent, J. (2020) ‘How COVID-19 “surveys” turned into a data-harvesting goldmine’, The Verge, 9 May.<br><br>
												BBC News (2023) ‘TikTok quiz scams trick users into sharing data’, BBC Technology, 12 June.<br><br>
												BCS (2023) BCS Code of Conduct. British Computer Society. Available at: https://www.bcs.org/membership-and-registrations/become-a-member/bcs-code-of-conduct/ (Accessed: 19 October 2025).<br><br>
												Confessore, N. (2018) ‘Cambridge Analytica and Facebook: The scandal and the fallout so far’, The New York Times, 4 April.<br><br>

											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3> Unit 6</h3>
											</header>
											<p>
												<strong>Reflection Summary</strong><br>
												This unit introduced quantitative methods as the study of numerical data to understand relationships between variables. It explained how data levels: nominal, ordinal, interval, and ratio determine which statistical tools are appropriate. Key topics included descriptive statistics such as measures of location (mean, median, mode) and dispersion (range, variance, standard deviation), as well as basic graphical summaries.<br><br>
												I learned that quantitative analysis is less about complex calculations and more about using the right method for the right type of data. In banking audit and technology, this is critical for interpreting trends, assessing anomalies, and supporting objective decisions. The distinction between descriptive and inferential statistics mirrors how auditors move from data summaries to evidence-based conclusions.<br><br>
												Going forward, I will use these principles to analyse financial data more effectively, applying visual and statistical summaries to detect patterns. The unit strengthened my belief that sound statistical reasoning is essential for transparency and credibility in professional decision-making.<br><br>
											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Unit 7</h3>
											</header>
											<p>
												<strong>Ethical Principles and the Role of Statistical Integrity in Research</strong><br><br>
												Before reading Corrêa et al. (2023), I had not realised how easily ethical principles can be compromised through something as routine as data analysis. The authors emphasise that fairness, accountability, and transparency are essential to trustworthy AI, but the same values apply to all areas of research. Choosing a convenient statistical method or reporting results selectively might appear harmless, yet it can distort truth and mislead decision makers.<br><br>
												Corrêa and colleagues argue that one of the biggest challenges in AI governance is building a shared ethical framework that works across cultures and disciplines. This resonates with broader research practice, where statistical choices can shape outcomes as much as the data itself. Floridi and Cowls (2021) remind us that the principles of beneficence and non-maleficence should guide every stage of technological development, ensuring innovation genuinely benefits society.<br><br>
												In real terms, researchers in areas such as healthcare or finance face strong incentives to present data favourably. Ioannidis (2005) warned years ago that selective reporting and weak statistical standards often produce unreliable findings. The same risks now exist in AI-driven studies. Upholding ethical standards means being transparent about methods, limitations, and uncertainty.<br><br>	
												Ultimately, research integrity depends less on regulation and more on individual responsibility. As Corrêa et al. (2023) show, global trust in AI and data science will rest on our willingness to remain honest in how we handle, interpret, and share information.<br><br>
													
												<strong>References</strong><br>
												Corrêa, N. K. et al. (2023) Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance. Patterns, 4(10), 100857<br><br>
												Floridi, L. and Cowls, J. (2021) A unified framework of five principles for AI in society. Harvard Data Science Review, 3(1).<br><br>
												Ioannidis, J. P. A. (2005) Why most published research findings are false. PLoS Medicine, 2(8), e124.<br><br>


												<strong>Hypothesis Testing Worksheet</strong><br><br>
												I coundn't find DATA SET G (Filtration.xlsx) file in the folder or I misunderstood the requirement. Therefore, I have only done the Exercise 7.2 below.<br><br>
												
												<strong>Exercise 7.2</strong><br><br>
												1. F-test for equal variances<br>
												•	F = 1.226<br>
												•	p = 0.436<br>
												•	Since p > 0.05, the variances between male and female incomes are not significantly different.<br>
												→ You can safely use the equal-variances t-test.<br><br>
												2. Independent-samples t-test<br>
												•	t = 3.268<br>
												•	Degrees of freedom ≈ 118<br>
												•	Two-tailed p = 0.0014<br>
												•	One-tailed p = 0.0007<br>
												Because p(one-tailed) < 0.05, you reject H₀ and conclude that male income is significantly higher than female income in the population.<br>
												
												<strong>Interpretation</strong><br>
												There is strong statistical evidence (t = 3.27, p = 0.0007, one-tailed) that the mean income of males exceeds that of females.<br>
												•	Male mean = 52.91 k<br>
												•	Female mean = 44.23 k<br>
												•	Estimated difference ≈ 8.68 k<br>
												Thus, males in this sample earn, on average, roughly 8½ units more than females.<br><br>


                                            <ul class="actions">
                                                <li><a href="artefacts/Exercise_7_2_Results_LB.xlsx" class="button" download target="_blank">Download artefact - Exercise 7.2</a></li>
                                            </ul>

	
											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Unit 8</h3>
											</header>
											<p>
												<strong>Reflection Summary on the Inference Worksheet</strong><br>
												It outlined the essential steps of hypothesis testing, from formulating null and alternative hypotheses to setting significance levels, computing test statistics, and making evidence-based decisions. The courtroom analogy was particularly effective in clarifying that the null hypothesis represents the presumption of innocence, which can only be rejected when evidence (data) makes it unlikely to be true.<br><br>
												A key takeaway for me was the importance of p-values and understanding that statistical testing does not “prove” a hypothesis but rather assesses the likelihood of observed outcomes. The discussion of Type I and Type II errors reinforced the idea that all statistical decisions carry risk and must balance caution with confidence.<br><br>
												Finally, the emphasis on setting hypotheses before analysing data underscored the ethical aspect of quantitative research. Manipulating tests after reviewing results compromises objectivity. This principle aligns closely with professional codes of conduct in computing and research, where integrity, transparency, and reproducibility are essential.<br><br>
												Overall, this unit deepened my understanding of how to apply statistical reasoning responsibly and interpret results with accuracy and honesty, which are vital skills for data-driven auditing and decision-making.<br><br>
											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3> Unit 9</h3>
											</header>
											<p>
												<strong>e-Portfolio Activity: Charts Worksheett</strong><br><br>
												
												<strong>Exercise 9.1 — Percentage bar chart (Area 2) + brief interpretation</strong><br><br>
													Using the raw records in your file, the percentage breakdowns are:<br>
												•	Area 1: A 15.71%, B 24.29%, Other 60.00%<br>
												•	Area 2: A 21.11%, B 33.33%, Other 45.56%<br>
												<strong>Interpretation</strong><br>
												Brand preferences differ by demographic area. Area 2 shows higher percentages for named brands A and B relative to Area 1, with a corresponding reduction in “Other.” This indicates stronger preference concentration on the listed brands in Area 2, whereas Area 1 respondents are more likely to choose alternatives outside A and B.<br><br>
												
												<ul class="actions">
                                                	<li><a href="artefacts/Exe 9.1D_LB.xlsx" class="button" download target="_blank">Download artefact - Exercise 9.1</a></li>
                                            	</ul><br><br>


												<strong>Exercise 9.2 — Clustered column chart (heather species prevalence)</strong><br><br>
												From the provided percentage table:<br>
												•	Location A: Absent 14.29%, Sparse 39.29%, Abundant 46.43%<br>
												•	Location B: Absent 45.45%, Sparse 31.82%, Abundant 22.73%<br>

												<strong>Interpretation</strong><br>
												Heather prevalence is markedly higher at Location A, with nearly half of observations classified as Abundant. Location B exhibits substantially greater Absent values and a lower Abundant proportion, indicating a less favourable habitat or conditions for heather at Location B.<br><br>
												
												<ul class="actions">
                                                <li><a href="artefacts/Exa 9.2E_LB.xlsx" class="button" download target="_blank">Download artefact - Exercise 9.2</a></li>
                                            	</ul><br><br>

												<strong>Exercise 9.3 — Relative frequency histogram (Diet B) using Diet A’s classes</strong><br><br>
												I used the common class scheme from the worksheet – this is to easy comparability with Diet A:<br>
												(-2, 0], (0, 2], (2, 4], (4, 6], (6, 8], (8, 10], (10, 12] and plotted Diet B accordingly, also regenerating Diet A for a clean visual comparison. Key sample statistics:<br>
												•	Diet A: n = 50, mean = 5.34 kg, SD = 2.54<br>
												•	Diet B: n = 50, mean = 3.71 kg, SD = 2.77<br><br>

												<strong>Interpretation</strong><br>
												The Diet A distribution centres on higher weight loss, with most mass in the 4–8 kg classes, consistent with its higher mean. Diet B has a larger share in the 2–4 kg range and fewer observations in the upper classes, reflecting lower overall weight loss. Dispersion is comparable though slightly greater for Diet B. Overall, Diet A yields greater average weight reduction.<br><br>
												
												<ul class="actions">
                                                <li><a href="artefacts/Exe 9.3B - LB.xlsx" class="button" download target="_blank">Download artefact - Exercise 9.2</a></li>
                                            	</ul><br><br>


											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Units 10 - 12</h3>
											</header>
											<p>
												<strong>Unit 10 - 12</strong><br>
												Preparation for the final reflection work included in Unit 12, including the submission of the e-Portfolio. <br><br>
											</p>
										</div>
									</div>
								</section>
					</div>

				<!-- Contact -->
					<section id="contact">
						<div class="inner">
							<section>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<label for="name">Name</label>
											<input type="text" name="name" id="name" />
										</div>
										<div class="field half">
											<label for="email">Email</label>
											<input type="text" name="email" id="email" />
										</div>
										<div class="field">
											<label for="message">Message</label>
											<textarea name="message" id="message" rows="6"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send Message" class="primary" /></li>
										<li><input type="reset" value="Clear" /></li>
									</ul>
								</form>
							</section>
							<section class="split">
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-envelope"></span>
										<h3>Email</h3>
										<a href="#">lucasrbennion@gmail.com</a>
									</div>
								</section>
							</section>
						</div>
					</section>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<ul class="icons">
								<li><a href="#" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
								<li><a href="#" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li>
								<li><a href="#" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
								<li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								<li><a href="#" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
							</ul>
							<ul class="copyright">
								<li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>