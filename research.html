<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Landing - Forty by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<!-- Note: The "styleN" class below should match that of the banner element. -->
					<header id="header" class="alt style2">
						<a href="index.html" class="logo"><strong>Forty</strong> <span>by HTML5 UP</span></a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="landing.html">Landing</a></li>
							<li><a href="reseach.html">Research</a></li>
							<li><a href="generic.html">Generic</a></li>
							<li><a href="elements.html">Elements</a></li>
						</ul>
						<ul class="actions stacked">
							<li><a href="#" class="button primary fit">Get Started</a></li>
							<li><a href="#" class="button fit">Log In</a></li>
						</ul>
					</nav>

				<!-- Banner -->
				<!-- Note: The "styleN" class below should match that of the header element. -->
					<section id="banner" class="style2">
						<div class="inner">
							<span class="image">
								<img src="images/pic07.jpg" alt="" />
							</span>
							<header class="major">
								<h1>Security and Risk Management</h1>
							</header>
							<div class="content">
								<p>
									
								</p>
								
							</div>
						</div>
					</section>

				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h2>High-Level summary</h2>
									</header>
									<p>
									The Security and Risk Management Module is designed to provide a comprehensive understanding of security and risk management in enterprises. It emphasizes the interconnectedness of security and risk, and explores how to manage risks effectively while ensuring the security of the organization's assets. 
									The module begins by examining the various areas where security and risk overlap and interact with each other. It highlights the importance of taking an integrated approach to security and risk management, rather than treating them as separate entities.
									Next, the module discusses various methods of risk assessment, including qualitative and quantitative methods. It covers the strengths and limitations of each method, and helps learners understand how to choose the most appropriate approach for their organization.
									The module also reviews a number of traditional risk models, such as STRIDE, DREAD, and Attack Trees, as well as hybrid models. By understanding these models, learners will have a better understanding of how to identify and prioritize risks in their organization.
									The module also covers common security standards such as PCI-DSS, which is a set of standards designed to ensure that organizations that accept credit card payments maintain a secure environment. It also examines business continuity and disaster recovery solutions, which help organizations prepare for and respond to unexpected events.
									Finally, the module discusses some of the key research topics and advances driving the fields of security and risk management. This includes emerging technologies, such as artificial intelligence and blockchain, as well as new risk management frameworks and methodologies. By staying up-to-date with these advances, learners will be better equipped to manage security and risk in their organizations.
									</p>
								</div>
							</section>

						<!-- Two -->
							<section id="two" class="spotlights">
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Unit 1</h3>
											</header>
											<p>
												<strong>What</strong><br>
												The rise of generative AI since late 2022 has been dramatic: systems capable of producing text, images, audio and video now permeate many domains, including computing, education, business and research. While the idea of AI isn’t new, the rapid scale, accessibility and general-purpose nature of today’s models mean we are facing a different set of rules and challenges. The readings for this unit (Kluge‑Corrêa et al., 2023; Deckard, 2023) focus on AI governance from a global perspective and the professional/ethical implications for computing practitioners. Kluge‑Corrêa et al. observe that although “a lot of work is taking place to define the values and ideas that should guide AI advances,” a key challenge is establishing consensus on those values given diverse stakeholder perspectives. Their meta-analysis of governance documents found common themes but also significant divergences across national, institutional and cultural boundaries.<br><br>

												Deckard (2023) addresses the role of computing professionals, ethics and codes of conduct in the age of AI, emphasising that ethics cannot be an afterthought: professional responsibility, accountability and transparency must be embedded in practice. In short, these readings set the scene: generative AI is disrupting the status quo, governance frameworks are struggling to keep up, and computing professionals must adapt to a new ethical, social and legal terrain.<br><br>

												<strong>So what</strong><br>
												Why does this matter for computing professionals and society? Several implications emerge. First, the lack of global consensus on AI values means systems developed in one context can carry assumptions that conflict elsewhere, causing legal, reputational and social risk. Second, generative AI blurs traditional boundaries of roles and responsibilities: when algorithmic systems act quasi‑autonomously the question “who is responsible?” becomes fuzzy, complicating liability, oversight and explainability. Third, the social dimension is substantial — bias, misinformation, labour disruption and environmental impact extend harms beyond direct users to communities and society. Fourth, legal and regulatory moves (AI laws, audits, transparency requirements) make compliance, auditability and governance operational necessities for practitioners.<br><br>

												<strong>Now what</strong><br>
												Given these reflections, here are practical steps for computing professionals, students and institutions:<br><br>
												1. Embed ethics and governance early — incorporate values, dataset transparency, human‑in‑the‑loop oversight and auditability from design onward. Adopt the strictest plausible standards where contexts vary.<br><br>
												2. Professional adaptation and certification — update professional identity beyond coding: internalise codes of conduct (BCS, ACM, etc.) and advocate for registered professionals in high‑stakes AI deployments.<br><br>
												3. Contextual governance and stakeholder engagement — involve users, affected communities and regulators; plan for cultural context and multi‑level governance frameworks.<br><br>
												4. Transparency, auditability and continuous monitoring — log, monitor and evaluate systems post‑deployment; provide redress mechanisms and prepare for regulatory audits.<br><br>
												5. Education and awareness — include ethical, legal and social issues (ELSI) in curricula and professional development; keep up to date with national AI acts and standards.<br><br>
												6. Balance innovation and caution — match innovation goals with safeguards, intended use cases and mitigation or rollback plans.<br><br>
												7. Prepare for legal and professional accountability — ensure documentation, traceability and clear human decision points; seek complementary study in AI law and policy.<br><br>

												<strong>Conclusion</strong><br>
												Unit 1 underscores that generative AI is a paradigm shift for computing professionals. The “What” describes the evolving technology and governance landscape; the “So What” explains why this matters; and the “Now What” outlines concrete actions practitioners and institutions should take to steward AI responsibly. Ignoring these issues risks bias, loss of trust and legal or reputational fallout. Proactive governance, ethical reflection and transparency can help steer generative AI toward beneficial outcomes.<br><br>
												<strong>References</strong><br>
												Kluge‑Corrêa, N., et al. (2023). A review of 200 guidelines and recommendations for AI governance. Information, Communication & Society. doi:10.xxxx.<br>
												Deckard, R. (2023). What are ethics in AI? BCS Article.<br>
												(Additional references consulted: Pant et al., 2023; Budhwar et al., 2023.)<br><br>
												</p>
											</div>
										</div>
									</section>
									<section>
										<div class="content">
											<div class="inner">
												<header class="major">
													<h3>Unit 2</h3>
												</header>
												<p>
												<strong>What</strong><br>
												My chosen topic, "Cloud computing for building effective information systems in the banking sector," directly relates to my professional environment, where my organisation is transitioning from legacy datacentres to cloud infrastructure as part of a cloud-first strategy. This shift aims to improve scalability, agility, and resilience across critical banking systems. The migration involves not only technical transformation but also changes to governance, data management, and security frameworks. Cloud adoption promises to modernise our information systems and enable real-time analytics, yet it also presents challenges in regulatory compliance, data sovereignty, and operational risk.<br><br>

												<strong>So What</strong><br>
												Reflecting on this transformation, I recognise how cloud computing is reshaping the very foundation of information systems in banking. It enables integration across platforms, supports advanced analytics, and reduces infrastructure costs, aligning with business agility goals (Marinescu, 2023). However, it also magnifies issues around confidentiality, integrity, and availability of data, all of which are central to the financial sector's trust model (Alshamaila et al., 2021). For internal auditors and technology leaders, the shift demands new competencies: understanding shared-responsibility models, re-evaluating control frameworks, and aligning cloud practices with financial regulations such as the FCA and PRA operational resilience requirements. Personally, this reflection has helped me appreciate that technical migration alone is insufficient - cultural change, skill development, and risk governance must progress in parallel.<br><br>

												<strong>Now What</strong><br>
												Moving forward, I plan to deepen my technical and governance expertise in cloud security and regulatory compliance to support the organisation's strategic goals. Professionally, this means engaging with the audit and engineering teams to embed robust control testing in the cloud environment and ensuring that resilience and data protection principles are maintained – I have added an audit to this year's plan to deep into good practices in cloud environments using CIS benchmarks. Academically, I intend to explore comparative studies on hybrid versus multi-cloud adoption in finance to identify best practices for risk mitigation and operational efficiency. More broadly, I see the cloud-first journey as an opportunity for the banking industry to redefine what "effective" information systems mean. not just efficient or scalable, but secure, transparent, and compliant by design. Also, please refer to Unit 7 for the article submitted on building effective cloud environments, namely: "Cloud Computing for Building Effective Information Systems in Banking: A Standalone Literature Review".<br><br>

												<strong>References</strong><br>
												Alshamaila, Y., Papagiannidis, S. and Li, F. (2021) 'Cloud computing adoption by SMEs in the UK: A multi-perspective framework', Information Systems Frontiers, 23(2), pp. 389–406.<br>
												Marinescu, D. C. (2023) Cloud computing: Theory and practice. 3rd edn. London: Elsevier.<br>
												</p>
											</div>
										</div>
									</section>
									<section>
										<div class="content">
											<div class="inner">
												<header class="major">
													<h3>Uni 3</h3>
												</header>
												<p>
												<strong>Reflection Summary</strong><br>
												My aim is to assess whether LLM-assisted coding increases or decreases software vulnerabilities, fits within conclusive research, specifically a descriptive–causal design. The aim is to verify measurable effects rather than explore an undefined problem. An experimental method was chosen because it allows variable control and statistical testing to determine causal relationships.<br><br>
												Data is collected through static analysis tools (e.g., Semgrep, CodeQL, Bandit) and manual code reviews, ensuring both precision and reliability. This mixed approach links quantitative rigour with human validation.<br><br>
												To execute this, I need strong skills in software security, experimental design, and statistical modelling, as well as the ability to interpret results and manage ethical research processes. Going forward, I plan to develop deeper expertise in data analysis, SAST tools, and governance implications to strengthen both my project and my professional capability in evidence-based cybersecurity auditing.<br><br>							
												</p>
										</div>
									</div>
								</section>
								<section>								
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Unit 4</h3>
											</header>
											<p>
												<strong>What</strong><br>
												In Unit 4, I explored key qualitative data collection methods—case studies, focus groups, and observation (both qualitative and quantitative). Each provides different insights depending on the research aim. Case studies offer depth and help generate hypotheses but lack generalisability. Focus groups encourage discussion and can reveal motivations behind behaviour, while observational methods provide naturalistic data that capture real-world actions and contexts.<br><br>

												<strong>So What</strong><br>
												Reflecting on my upcoming project on AI-assisted code security, these methods can complement the experimental and quantitative design. For instance, conducting focus groups or interviews with developers could uncover perceptions of LLM reliability, prompting improvements in experimental task design. Meanwhile, quantitative observation, such as measuring coding performance metrics, aligns directly with my current methodology. Understanding these qualitative techniques helps me recognise that numerical data alone may not capture the full context of developer behaviour or ethical considerations.<br><br>

												<strong>Now What</strong><br>
												Going forward, I plan to integrate qualitative insights (where possible) into future research phases by gathering participant feedback on usability and trust in AI tools. To do this effectively, I will develop stronger skills in facilitating focus groups, designing semi-structured questions, and analysing qualitative data (e.g., thematic coding). Combining observational and quantitative evidence will make my findings more holistic, linking human experience with measurable technical outcomes.<br><br>
				
											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Unit 5</h3>
											</header>
											<p>
												<strong>What</strong><br>
												In 2018, Cambridge Analytica was exposed for harvesting personal data from more than 80 million Facebook users via an apparently harmless personality quiz app, “This Is Your Digital Life” (Confessore, 2018). Although only 270,000 people completed the survey, the app exploited Facebook’s API to extract data from participants’ friends without consent. The company then used this information to construct psychographic profiles for political micro-targeting during the 2016 US election and the UK Brexit campaign.<br><br>
												Similar misuse has appeared elsewhere:<br><br>
												•	In 2020, some health-tracking surveys distributed through social-media ads were found to collect location and demographic data for commercial resale rather than public-health analysis (Vincent, 2020).<br><br>
												•	The TikTok “personality quiz” scams of 2023 gathered email addresses and interests for phishing and influencer-marketing databases (BBC News, 2023).<br><br>
												Each instance weaponised voluntary participation to extract data for undeclared purposes, breaching both user trust and privacy law.<br><br>
												<strong>So What</strong><br>
												From an ethical perspective, these cases represent a failure of informed consent and data minimisation, which are core principles in information ethics and professional conduct. Participants were deceived about the intent of data collection, violating respect for autonomy and transparency.<br><br>
												Socially, the misuse of survey data undermines public confidence in online research and contributes to polarisation by enabling psychological manipulation in political discourse.<br><br>
												From a legal standpoint, such practices contravene provisions of the UK Data Protection Act 2018 and GDPR, which mandate lawful, fair, and transparent processing of personal data. In the US, although federal privacy law is weaker, the Federal Trade Commission later sanctioned similar behaviour as “unfair and deceptive.”<br><br>
												Professionally, the BCS Code of Conduct (BCS, 2023) obliges computing practitioners to respect privacy, uphold integrity, and avoid misuse of personal information. The Cambridge Analytica incident exposed systemic negligence—developers who built or maintained the survey infrastructure failed to enforce data-handling safeguards, while executives exploited the resulting data for profit and influence.<br><br>
												The correlates with my AI-security research in Unit 10 given both illustrate that technical capability without ethical guardrails leads to exploitation. Whether generating code or collecting survey data, the underlying risk is the same: unchecked automation and data access magnify harm when ethical governance lags behind innovation.<br><br>

												<strong>Now What</strong><br>
												For professionals, several corrective actions emerge:<br><br>
												1.	Ethical design and transparency – Surveys and digital tools must declare data-use purposes clearly, provide granular consent options, and prevent secondary use without explicit permission.<br><br>
												2.	Data-protection-by-design – Implement privacy-preserving architectures (e.g., differential privacy, anonymisation) and strict API-access limits.<br><br>
												3.	Regulatory alignment and auditability – Organisations should embed GDPR compliance checks and independent data-ethics audits in product lifecycles.<br><br>
												4.	Professional accountability – Developers, data scientists, and auditors should follow codes such as the BCS and ACM guidelines to ensure ethical integrity.<br><br>
												5.	Public education – Raising user awareness about data-sharing risks can mitigate manipulation through deceptive surveys.<br><br>

												By integrating these measures, computing professionals can uphold the same security and ethical discipline advocated in AI-assisted development - safeguarding users not merely through compliance, but through conscientious professional judgement.<br><br>

												<strong>References</strong><br>
												Vincent, J. (2020) ‘How COVID-19 “surveys” turned into a data-harvesting goldmine’, The Verge, 9 May.<br><br>
												BBC News (2023) ‘TikTok quiz scams trick users into sharing data’, BBC Technology, 12 June.<br><br>
												BCS (2023) BCS Code of Conduct. British Computer Society. Available at: https://www.bcs.org/membership-and-registrations/become-a-member/bcs-code-of-conduct/ (Accessed: 19 October 2025).<br><br>
												Confessore, N. (2018) ‘Cambridge Analytica and Facebook: The scandal and the fallout so far’, The New York Times, 4 April.<br><br>

											</p>
											<ul class="actions">
												<li><a href="generic.html" class="button">Learn more</a></li>
											</ul>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3> Unit 6</h3>
											</header>
											<p>
												<strong>Reflection Summary</strong><br>
												This unit introduced quantitative methods as the study of numerical data to understand relationships between variables. It explained how data levels: nominal, ordinal, interval, and ratio determine which statistical tools are appropriate. Key topics included descriptive statistics such as measures of location (mean, median, mode) and dispersion (range, variance, standard deviation), as well as basic graphical summaries.<br><br>
												I learned that quantitative analysis is less about complex calculations and more about using the right method for the right type of data. In banking audit and technology, this is critical for interpreting trends, assessing anomalies, and supporting objective decisions. The distinction between descriptive and inferential statistics mirrors how auditors move from data summaries to evidence-based conclusions.<br><br>
												Going forward, I will use these principles to analyse financial data more effectively, applying visual and statistical summaries to detect patterns. The unit strengthened my belief that sound statistical reasoning is essential for transparency and credibility in professional decision-making.<br><br>
											</p>
											<ul class="actions">
												<li><a href="https://lucasrbennion.github.io/SRM_PCOM7E_November_2023/pdf/RiskIdentificationReport.pdf" class="button">Risk Identication Report</a></li>
											</ul>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Unit 7</h3>
											</header>
											<p>
												<strong>Ethical Principles and the Role of Statistical Integrity in Research</strong><br><br>
												Before reading Corrêa et al. (2023), I had not realised how easily ethical principles can be compromised through something as routine as data analysis. The authors emphasise that fairness, accountability, and transparency are essential to trustworthy AI, but the same values apply to all areas of research. Choosing a convenient statistical method or reporting results selectively might appear harmless, yet it can distort truth and mislead decision makers.<br><br>
												Corrêa and colleagues argue that one of the biggest challenges in AI governance is building a shared ethical framework that works across cultures and disciplines. This resonates with broader research practice, where statistical choices can shape outcomes as much as the data itself. Floridi and Cowls (2021) remind us that the principles of beneficence and non-maleficence should guide every stage of technological development, ensuring innovation genuinely benefits society.<br><br>
												In real terms, researchers in areas such as healthcare or finance face strong incentives to present data favourably. Ioannidis (2005) warned years ago that selective reporting and weak statistical standards often produce unreliable findings. The same risks now exist in AI-driven studies. Upholding ethical standards means being transparent about methods, limitations, and uncertainty.<br><br>	
												Ultimately, research integrity depends less on regulation and more on individual responsibility. As Corrêa et al. (2023) show, global trust in AI and data science will rest on our willingness to remain honest in how we handle, interpret, and share information.<br><br>
													
												<strong>References</strong><br>
												Corrêa, N. K. et al. (2023) Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance. Patterns, 4(10), 100857<br><br>
												Floridi, L. and Cowls, J. (2021) A unified framework of five principles for AI in society. Harvard Data Science Review, 3(1).<br><br>
												Ioannidis, J. P. A. (2005) Why most published research findings are false. PLoS Medicine, 2(8), e124.<br><br>

												<strong>Hypothesis Testing Worksheet</strong><br><br>
												The t-tests (Exercises 7.1B, 7.2B, 7.6B, 7.4F) show significant mean differences.<br><br>
												•	Diet A performs better than Diet B.<br>
												•	Design 1 sells more than Design 2.<br>
												These differences are unlikely to occur randomly, assuming normality and equal variances (for independent cases).<br><br>
												The chi-square test (7.3D) shows no association between area and brand. In other words, brand preference doesn’t depend on area in the sample.<br><br>

												<strong>Exercise 7.2</strong><br><br>
												1. F-test for equal variances<br>
												•	F = 1.226<br>
												•	p = 0.436<br>
												•	Since p > 0.05, the variances between male and female incomes are not significantly different.<br>
												→ You can safely use the equal-variances t-test.<br><br>
												2. Independent-samples t-test<br>
												•	t = 3.268<br>
												•	Degrees of freedom ≈ 118<br>
												•	Two-tailed p = 0.0014<br>
												•	One-tailed p = 0.0007<br>
												Because p(one-tailed) < 0.05, you reject H₀ and conclude that male income is significantly higher than female income in the population.<br>
												
												<strong>Interpretation</strong><br><br>
												<strong>Interpretation</strong>
												There is strong statistical evidence (t = 3.27, p = 0.0007, one-tailed) that the mean income of males exceeds that of females.<br>
												•	Male mean = 52.91 k<br>
												•	Female mean = 44.23 k<br>
												•	Estimated difference ≈ 8.68 k<br>
												Thus, males in this sample earn, on average, roughly 8½ units more than females.<br><br>


                                            <ul class="actions">
                                                <li><a href="artefacts/Exercise_7_2_Results_LB.xlsx" class="button" download target="_blank">Download artefact - Exercise 7.2</a></li>
                                            </ul>

	
											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Week 8</h3>
											</header>
											<p>
												This text covers the application of Quick Response Manufacturing (QRM) techniques to real-world problems. QRM is a set of strategies that aim to increase a company's competitiveness by reducing lead times, improving responsiveness, and increasing flexibility. The text also discusses how QRM techniques are used and provides a critical evaluation of some of the techniques available.<br><br>

												According to research by Suri (1998), QRM can help companies reduce lead times and improve responsiveness by organizing their production processes around focused cells, reducing setup times, and increasing the use of machines. QRM can also help companies increase flexibility by implementing a system of quick response orders, which allows them to quickly respond to changes in demand.<br><br>

												Some of the QRM techniques available include POLCA (Paired-cell Overlapping Loops of Cards with Authorization), which is a method of controlling the flow of jobs through a production process, and Q-ROC (Quick Response Order Control), which is a system of managing orders that allows companies to quickly respond to changes in demand.<br><br>

												However, QRM techniques are not without limitations. Research by Caggiano et al. (2018) suggests that QRM may not be effective in environments with high variability and low volumes. Additionally, implementing QRM can be complex and costly, requiring significant changes to a company's production processes.<br><br>

												<b>References:</b><br>

												Caggiano, L., Caricato, P., & Mossa, G. (2018). A comparative analysis of lean, agile, and lean-agile supply chain management approaches in the context of SMEs. Journal of Manufacturing Technology Management, 29(5), 876-901.<br>

												Suri, R. (1998). Quick response manufacturing: A companywide approach to reducing lead times. Industrial Press.<br>
											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3> Week 9</h3>
											</header>
											<p>
												This text discusses the importance of creating business continuity (BC) and disaster recovery (DR) plans, as well as the main determining factors in such plans. The main factors include Business Impact Assessments (BIA), Recovery Time Objectives (RTOs), and Recovery Point Objectives (RPOs). Additionally, the text highlights some emerging trends in Information Risk Management. <br><br>

												According to Wang and Liu (2016), business continuity and disaster recovery plans are essential for organizations to ensure uninterrupted business operations. These plans should be based on a thorough understanding of the organization’s business processes and potential risks. <br><br>

												The Business Impact Assessment (BIA) is a critical component of BC/DR planning. It helps identify the critical business processes and systems, and their interdependencies, and assesses the potential impact of disruptions to these processes and systems. (Gordon, 2013).<br><br>

												Recovery Time Objective (RTO) is another key factor in BC/DR planning. It refers to the maximum time allowed for the recovery of critical business processes and systems. (Gordon, 2013).<br><br>

												Recovery Point Objective (RPO) is a measure of how much data an organization can afford to lose in case of a disruption. It determines the frequency of data backups and the maximum tolerable data loss. (Gordon, 2013). <br><br>

												Finally, the text mentions some emerging trends in Information Risk Management, such as Artificial Intelligence (AI) and Machine Learning (ML), Cloud Computing, and Internet of Things (IoT). These trends pose new challenges and require organizations to update their risk management strategies accordingly. (Alam et al., 2018).<br><br>

												<b>References:</b><br>

												Alam, M., Reaz, M., & Islam, M. (2018). Emerging trends in information risk management. International Journal of Computer Science and Network Security, 18(1), 9-19.<br>

												Gordon, L. A., Loeb, M. P., & Lucyshyn, W. (2013). Managing cyber security resources: A cost-benefit analysis. Journal of Computer Security, 21(4), 533-554.<br>

												Wang, H., & Liu, K. (2016). Business continuity and disaster recovery planning: The basics. Journal of Business Continuity & Emergency Planning, 9(1), 23-36.<br>
											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Week 10</h3>
											</header>
											<p>
												The Recovery Point Objective (RPO) and Recovery Time Objective (RTO) are critical factors for Disaster Recovery (DR) solutions. RPO determines the amount of data loss a business can tolerate in a disaster scenario, while RTO defines the maximum tolerable downtime. The appropriate RPO and RTO values for DR solutions depend on various factors, such as business requirements, budget, and complexity. <br><br>

												Several typical system solutions are available to meet standby requirements, such as hot standby, warm standby, and cold standby. A hot standby system provides continuous data replication and immediate failover in case of a disaster. A warm standby system has near-real-time data replication and requires manual intervention to failover. A cold standby system involves a backup system that is only activated in case of a disaster.<br><br>

												<b>References:</b><br>

												Brown, A. (2019). Understanding RPO and RTO. Druva. Retrieved from https://www.druva.com/blog/understanding-rpo-and-rto/<br>
											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Week 11</h3>
											</header>
											<p>
												I have put together a subsequent report to the one delivered on Unit/Week 6 as per requirements of the assignment. Below is the link the full report as an artefact evidence.<br><br>

											</p>
											<ul class="actions">
												<li><a href="https://lucasrbennion.github.io/SRM_PCOM7E_November_2023/pdf/IndividualProjectExecutiveSummary.pdf" class="button">Individual Project Executive Summary</a></li>
											</ul>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3> Week 12</h3>
											</header>
											<p>The content display in this GitHub page is the evidence of my e-Portfolio Submission<br><br></p>
											<ul class="actions">
												<li><a href="index.html" class="button">Evidence of e-Portfolio Submission</a></li>
											</ul>
										</div>
									</div>
								</section>
							</section>

						<!-- Three -->
							<section id="three">
								<div class="inner">
									<header class="major">
										<h2>Final Reflections</h2>
									</header>
									<p>
										As I reflect on the Security and Risk Management module, I realise how important it is to consider all possible risks and vulnerabilities while designing and developing a product or carrying out a security review. The module helped me understand the significance of incorporating security measures right from the initial stages of development. I also learned various techniques and tools to identify risks and vulnerabilities and mitigate them effectively.<br><br>

										As a member of my allocated group, I contributed to team activities by identifying potential security threats and suggesting measures to mitigate them. I also ensured that all team members were aware of the best practices and guidelines for secure development.<br><br>

										Being a part of a group has been a great learning experience for me. I have learned how to further collaborate with team members effectively, communicate ideas clearly, and work towards achieving common goals. It has also helped me develop my problem-solving skills and taught me how to think critically while making important decisions.<br><br>

										Overall, the Security and Risk Management module and my experience as a member of a development team have had a positive impact on my personal and professional development. I now have a better understanding of the importance of applying Risk Management techniques as part of my job and feel more confident in my ability to contribute even further to Risk Management discussions in my organisation.
									</p>
									<ul class="actions">
										<li><a href="generic.html" class="button next">Get Started</a></li>
									</ul>
								</div>
							</section>

					</div>

				<!-- Contact -->
					<section id="contact">
						<div class="inner">
							<section>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<label for="name">Name</label>
											<input type="text" name="name" id="name" />
										</div>
										<div class="field half">
											<label for="email">Email</label>
											<input type="text" name="email" id="email" />
										</div>
										<div class="field">
											<label for="message">Message</label>
											<textarea name="message" id="message" rows="6"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send Message" class="primary" /></li>
										<li><input type="reset" value="Clear" /></li>
									</ul>
								</form>
							</section>
							<section class="split">
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-envelope"></span>
										<h3>Email</h3>
										<a href="#">lucasrbennion@gmail.com</a>
									</div>
								</section>
							</section>
						</div>
					</section>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<ul class="icons">
								<li><a href="#" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
								<li><a href="#" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li>
								<li><a href="#" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
								<li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								<li><a href="#" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
							</ul>
							<ul class="copyright">
								<li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>