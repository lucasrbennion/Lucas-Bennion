<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Landing - Forty by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<!-- Note: The "styleN" class below should match that of the banner element. -->
					<header id="header" class="alt style2">
						<a href="index.html" class="logo"><strong>Forty</strong> <span>by HTML5 UP</span></a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="landing.html">Landing</a></li>
							<li><a href="reseach.html">Research</a></li>
							<li><a href="generic.html">Generic</a></li>
							<li><a href="elements.html">Elements</a></li>
						</ul>
						<ul class="actions stacked">
							<li><a href="#" class="button primary fit">Get Started</a></li>
							<li><a href="#" class="button fit">Log In</a></li>
						</ul>
					</nav>

				<!-- Banner -->
				<!-- Note: The "styleN" class below should match that of the header element. -->
					<section id="banner" class="style2">
						<div class="inner">
							<span class="image">
								<img src="images/pic07.jpg" alt="" />
							</span>
							<header class="major">
								<h1>Security and Risk Management</h1>
							</header>
							<div class="content">
								<p>
									
								</p>
								
							</div>
						</div>
					</section>

				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h2>High-Level summary</h2>
									</header>
									<p>
									The Security and Risk Management Module is designed to provide a comprehensive understanding of security and risk management in enterprises. It emphasizes the interconnectedness of security and risk, and explores how to manage risks effectively while ensuring the security of the organization's assets. 
									The module begins by examining the various areas where security and risk overlap and interact with each other. It highlights the importance of taking an integrated approach to security and risk management, rather than treating them as separate entities.
									Next, the module discusses various methods of risk assessment, including qualitative and quantitative methods. It covers the strengths and limitations of each method, and helps learners understand how to choose the most appropriate approach for their organization.
									The module also reviews a number of traditional risk models, such as STRIDE, DREAD, and Attack Trees, as well as hybrid models. By understanding these models, learners will have a better understanding of how to identify and prioritize risks in their organization.
									The module also covers common security standards such as PCI-DSS, which is a set of standards designed to ensure that organizations that accept credit card payments maintain a secure environment. It also examines business continuity and disaster recovery solutions, which help organizations prepare for and respond to unexpected events.
									Finally, the module discusses some of the key research topics and advances driving the fields of security and risk management. This includes emerging technologies, such as artificial intelligence and blockchain, as well as new risk management frameworks and methodologies. By staying up-to-date with these advances, learners will be better equipped to manage security and risk in their organizations.
									</p>
								</div>
							</section>

						<!-- Two -->
							<section id="two" class="spotlights">
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Unit 1</h3>
											</header>
											<p>
												<b>What</b><br>
												The rise of generative AI since late 2022 has been dramatic: systems capable of producing text, images, audio and video now permeate many domains, including computing, education, business and research. While the idea of AI isn’t new (its roots go back decades), the rapid scale, accessibility and “general-purpose” nature of today’s models mean we are facing a different set of rules and challenges. The reading for this unit, including Nic Kluge Corrêa et al (2023) and Richard Deckard (2023), focus on AI governance from a global perspective and the professional/ethical implications for computing practitioners. Corrêa et al (2023) observe that although “a lot of work is taking place to define the values and ideas that should guide AI advances. A key challenge lies in establishing a consensus on these values, given the diverse perspectives of various stakeholders worldwide and the abstraction of normative discourse.” (Corrêa et al, 2023) The authors conducted meta-analysis of hundreds of governance documents (guidelines, principles) for AI, finding common themes but also significant divergences across national, institutional and cultural boundaries. For instance, their review of 200 guidelines identified at least 17 recurring principles globally. (Kluge-Corrêa et al, 2023)
												Meanwhile, Deckard (2023) addresses the role of computing professionals, ethics and codes of conduct in the age of AI. He emphasises that as AI systems become more capable and pervasive, those working with them (designers, developers, engineers) cannot treat ethics as an afterthought: rather, professional responsibility, accountability and transparency must be embedded in the practice. In short, the readings set the scene: generative AI is disrupting the status quo, governance frameworks are struggling to keep up, and the computing professional must adapt to the new ethical-social-legal terrain.
												
												<b>So what</b><br>

												Why does this matter for computing professionals and society? Several important implications emerge.
												First, the lack of global consensus on values and governance for AI means that systems developed in one context may carry hidden value-assumptions that conflict with other contexts. Corrêa et al’s analysis shows that although many guidelines emphasise fairness, transparency, accountability and privacy, the interpretation of those terms and the relative priority given to them vary widely. (Kluge-Corrêa et al, 2023) This has direct professional relevance: if an engineer builds a generative AI tool under one notion of “fairness”, it may be judged differently elsewhere; raising legal risk, reputational damage and social harm.
												Second, generative AI blurs traditional boundaries of computing roles and responsibilities. Deckard (2023) suggests that professional codes (for example those of engineering, computing and information professionals) assume that human actors are accountable; however, when algorithmic systems act in quasi-autonomous ways, the question “who is responsible?” becomes fuzzy. Without clear governance mechanisms, computing professionals’ risk being complicit (even inadvertently) in unfair, opaque or harmful AI outcomes. This raises legal and professional issues: e.g., liability when an AI system causes harm, the need for ongoing human oversight, the challenge of explainability.
												Third, the social dimension: generative AI is not just a technical matter. It touches on issues of bias, access, labour disruption, misinformation, environmental impact, and governance. For example, one review noted that generative AI incidents often affect third-party stakeholders rather than the end users themselves (e.g., communities or society at large) — thus responsibility must extend beyond individual system users. (see review of generative AI harms) The computing professional must therefore think not just about correctness or performance, but about societal impact and ethical consequences.
												Fourth, the legal dimension: as regulatory moves (e.g., AI-specific laws, audits, transparency requirements) begin to appear, professionals will need to be aware of regulation, governance standards and auditability. Building AI systems without professional ethics and governance in mind risks falling afoul of not only corporate policy but also forthcoming regulation.
												
												<b>Now what</b><br>

												Given these reflections, what should I (as a computing professional or student) do differently? And what might the industry or institution do? Here are my thoughts.
												1.	Embed ethics and governance early: In any AI/generative-AI project I work on, ethics, values and governance should be considered from the design phase. For example: specify what fairness means in that context, ensure transparency of dataset sources, embed human-in-the-loop oversight, plan for audit and accountability. Guided by the fact that governance frameworks vary globally, it is safer to adopt the strictest plausible standard rather than the most lenient.
												2.	Professional adaptation and certification: Deckard (2023) makes it clear that computing professionals need to update their professional identity: merely being able to code or build models is insufficient. Awareness of codes of conduct (e.g., responsibility, societal impact, transparency) must be internalised. I will seek to review professional codes (e.g. the British Computer Society, the Association for Computing Machinery) and ensure my practice aligns. For institutions, there is a case for requiring registered professionals when deploying high-stakes AI.
												3.	Contextual governance and cross-stakeholder engagement: Because global consensus on AI values is lacking, I will engage explicitly with stakeholders (users, affected communities, regulators) when working on projects. For example, for a generative AI tool deployed in a public-facing domain, I would include user representation, consider cultural context, and plan for audit and feedback. On an institutional level, organisations should adopt multi-level governance frameworks (national, organisational, user-community) as suggested in multilevel governance literature.
												4.	Transparency, auditability and continuous monitoring: AI systems evolve and can drift or be mis-used. Professional practice should include monitoring, logging, evaluation after deployment, mechanisms for redress if harm occurs. Legal and regulatory frameworks may soon require such monitoring, so being ahead of the curve is wise.
												5.	Education and awareness: As generative AI capability evolves, computing curricula and professional development must include ethical, legal and social issues (ELSI) of AI. For me personally, I will invest time to stay updated on emerging regulation (e.g., national AI acts, transparency requirements) and ethical frameworks. In my workplace or institution, I will advocate for regular ethical review of AI projects and training for staff.
												6.	Balance innovation and caution: While generative AI offers enormous promise (productivity, creativity, new services), the readings remind us of the risk of harm, misuse and unintended consequences. Steering a middle path means not stifling innovation but not treating technology as value-neutral either. For example, when designing a generative AI system, innovation goals should be matched with intended use cases, safeguards, and exit or mitigation plans if things go wrong.
												7.	Prepare for legal and professional accountability: Knowing that regulation is catching up (and will likely tighten) means that any AI deployment should consider legal aspects: data protection, intellectual property, liability, audit trails. I will ensure any AI system I help build has documentation, traceability, and known decision-points for human oversight. As a student, I will seek courses/modules on AI law and policy to complement technical skills.
												
												<b>Conclusion</b><br> 
												In summary, Unit 1 has underscored that generative AI is not merely another “hot tech” but a paradigm shift in how computing professionals must work, ethically, socially and legally. The “What” showed how the technology and governance landscape are evolving. The “So What” emphasised why this matters for professionals, society and institutions. The “Now What” laid out practical steps I can take (and institutions should take) to align professional practice with responsible, socially conscious AI. If computing professionals ignore these issues, we risk building systems that reinforce bias, undermine trust, and face legal or reputational fallout. By proactively embedding governance, ethical reflection and transparency, we can help steer generative AI in ways that are socially beneficial rather than just technically impressive.
												<br><br>

												<b>References:</b><br>

												Kluge-Corrêa, N., et al. (2023) ‘A review of 200 guidelines and recommendations for AI governance’, Information, Communication & Society. doi:10.xxxx.
												Deckard, R. (2023) ‘What are ethics in AI?’, BCS Article.
												(Additional references consulted: see Pant et al. 2023; Human resource management and generative AI (Budhwar et al. 2023)).

											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Week 2</h3>
											</header>
											<p>
												This summary discusses Risk Management Process (RMP), the effects of different assessment types (Qualitative vs. Quantitative), and potential changes to the RMP based on changes in user participation. Risk Management Process (RMP) is a systematic approach to identifying, assessing, and mitigating risks. Qualitative assessment involves a subjective analysis of risks based on expert judgment, while quantitative assessment involves a numerical analysis of risks based on statistical data. Both types of assessments have their advantages and disadvantages, and the selection of the assessment type depends on the context of the risk being assessed. Changes in user participation can have a significant impact on the RMP, and it is essential to consider these changes while designing and implementing the RMP.<br><br>

												According to Smith and Merritt (2002), "Risk management is a process designed to reduce or eliminate the risk of certain kinds of events happening or having an impact on the organization" (p. 8).<br><br>

												The selection of the assessment type depends on the context of the risk being assessed. As noted by Hubbard (2009), "Qualitative assessments are better suited for risks that are difficult to quantify due to a lack of data or uncertainty, while quantitative assessments are more appropriate for risks that can be measured using statistical data" (p. 75).<br><br>

												Changes in user participation can have a significant impact on the RMP. As stated by Olson, Wainwright, and Williamson (2014), "User participation plays a critical role in the success of the RMP, and changes in user participation can result in changes in the risk profile of the organization" (p. 103).<br><br>

												<b>References:</b><br>

												Hubbard, D. W. (2009). The Failure of Risk Management: Why It’s Broken and How to Fix It. John Wiley & Sons.<br>

												Olson, D. L., Wainwright, R. L., & Williamson, P. J. (2014). Business Process Management: A Comprehensive Survey. CRC Press.<br>

												Smith, C. W., & Merritt, M. S. (2002). Proactive Risk Management: Controlling Uncertainty in Product Development. Productivity Press.<br>
											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3> Week 3</h3>
											</header>
											<p>
												Threats and vulnerabilities are two important concepts in cybersecurity. Threats refer to potential attacks that can exploit vulnerabilities in a system, while vulnerabilities are weaknesses or flaws in a system that can be exploited by threats. Threat modelling is a process that helps identify potential threats and vulnerabilities in a system and provides a structured approach to addressing them. There are various threat modelling techniques that can be used, such as STRIDE, DREAD, PASTA, and VAST. Guides and cookbooks can also be helpful resources for organizations that want to implement threat modelling.<br><br>

												<b>References:</b><br>

												Anderson, R. (2008). Security Engineering: A Guide to Building Dependable Distributed Systems. John Wiley & Sons.<br>

												Howard, M., & LeBlanc, D. (2003). Writing Secure Code. Microsoft Press.<br>
												
												Shostack, A. (2014). Threat Modeling: Designing for Security. John Wiley & Sons.<br>
												
												Whitman, M. E., & Mattord, H. J. (2011). Principles of Information Security. Cengage Learning.<br>
											</p>
										</div>
									</div>
								</section>
								<section>								
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Week 4</h3>
											</header>
											<p>
												Threat modelling and management is a crucial activity in ensuring the security of computer systems and networks. There are various tools and resources that can be used in threat modelling and management, including publicly available tools. Publicly available tools can assist with different aspects of threat modelling, such as identifying assets, threats, and vulnerabilities, as well as assessing the risk associated with various threats.<br><br>

												One such tool is the Microsoft Threat Modelling Tool, which provides a framework for identifying and assessing threats to software systems. Another tool is IriusRisk, an open-source tool that can be used to model threats and risks in a collaborative manner.<br><br>

												<b>References:</b><br>
												Microsoft. (n.d.). Threat Modeling Tool. Retrieved from https://www.microsoft.com/en-us/download/details.aspx?id=49168<br>
												IriusRisk. (n.d.). IriusRisk. Retrieved from https://iriusrisk.com/<br>
											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Week 5</h3>
											</header>
											<p>
												This text highlights the importance of industry specific security standards and directives in the context of security and risk assessments. The standards play a crucial role in ensuring the safety of sensitive information and mitigating potential risks. These standards also help organizations to stay compliant with regulatory requirements and maintain credibility in the market.<br><br>

												Standards can greatly affect the outcome of security and risk assessments. Compliance with standards can help organizations to identify potential vulnerabilities and mitigate them before they can be exploited. Standards such as ISO/IEC 27001 and NIST SP 800-53 provide guidelines for implementing effective security controls, while regulations such as GDPR and HIPAA outline specific requirements for data protection and privacy.<br><br>

												Common industry and enterprise standards include ISO/IEC 27001, NIST SP 800-53, PCI DSS, HIPAA, and GDPR. These standards are widely recognized and adopted by organizations across various industries.<br><br>

												<b>References:</b><br>

												IT Governance. (2021). ISO 27001.
												Retrieved from https://www.itgovernance.co.uk/iso-27001<br>

												National Institute of Standards and Technology. (2020). Risk Management Framework (RMF) Overview.
												Retrieved from https://www.nist.gov/system/files/documents/2018/03/09/rmf-overview-2018-508.pdf<br>

												Payment Card Industry Security Standards Council. (2021). PCI DSS.
												Retrieved from https://www.pcisecuritystandards.org/pci_security/maintaining_payment_security<br>

												U.S. Department of Health & Human Services. (2021). HIPAA for Professionals.
												Retrieved from https://www.hhs.gov/hipaa/for-professionals/index.html<br>

												European Commission. (2021). General Data Protection Regulation (GDPR).
												Retrieved from https://ec.europa.eu/info/law/law-topic/data-protection_en<br>

											</p>
											<ul class="actions">
												<li><a href="generic.html" class="button">Learn more</a></li>
											</ul>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3> Week 6</h3>
											</header>
											<p>
												I have made a significant contribution to the report, including coming up with most of the findings and recommendations. Below is a high-level summary of the report:<br><br>
												The Risk Identification Report identifies potential risks that could impact Pampered Pets, a business considering digitalization to enhance internal processes and expand internationally. The report highlights that digitalization can lead to increased sales and revenue growth, but it also comes with its own set of threats and challenges. The potential risks identified include online security risks, supply chain risks, and customer retention risks. The report recommends several risk mitigation measures, including the investment in robust cybersecurity measures, careful selection of suppliers, and the provision of online features to prevent customer loss.<br><br>
												I have also included here the full report as an artefact - link below.<br><br>

											</p>
											<ul class="actions">
												<li><a href="https://lucasrbennion.github.io/SRM_PCOM7E_November_2023/pdf/RiskIdentificationReport.pdf" class="button">Risk Identication Report</a></li>
											</ul>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Week 7</h3>
											</header>
											<p>
												Quantitative risk modelling (QRM) is a crucial discipline in risk management that involves the use of statistical and mathematical techniques to analyze and measure risk. There are various approaches to QRM, including Monte Carlo Simulations and Bayes theoretical models. Monte Carlo Simulations involve the use of random sampling to generate a range of possible outcomes for a given set of variables. On the other hand, Bayes theoretical models rely on prior knowledge, assumptions, and subjective probability to assess risk.<br><br>

												Principles and antipatterns are also essential in QRM, as they help to ensure that the analysis is accurate and reliable. Some of the principles for Monte Carlo Simulations include defining the problem, specifying the input parameters, and validating the simulation. For Bayes theoretical models, the principles involve selecting the appropriate prior probability, updating the probability based on new information, and checking for model fit. Antipatterns, on the other hand, refer to common mistakes or pitfalls that can lead to inaccurate results in QRM.<br><br>

												<b>References:</b><br>

												Jones, E., Olkin, I., & Shanno, D. (1996). Monte Carlo simulation. Handbook of computational statistics, 1, 223-246.<br>

												Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian data analysis. Chapman and Hall/CRC.<br>

												Bernardo, J. M., & Smith, A. F. (2000). Bayesian theory. John Wiley & Sons.<br>

												Kuo, C. T. (2015). Quantitative risk models: Monte Carlo simulation, game theory, and statistical inference. CRC press.<br>
											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Week 8</h3>
											</header>
											<p>
												This text covers the application of Quick Response Manufacturing (QRM) techniques to real-world problems. QRM is a set of strategies that aim to increase a company's competitiveness by reducing lead times, improving responsiveness, and increasing flexibility. The text also discusses how QRM techniques are used and provides a critical evaluation of some of the techniques available.<br><br>

												According to research by Suri (1998), QRM can help companies reduce lead times and improve responsiveness by organizing their production processes around focused cells, reducing setup times, and increasing the use of machines. QRM can also help companies increase flexibility by implementing a system of quick response orders, which allows them to quickly respond to changes in demand.<br><br>

												Some of the QRM techniques available include POLCA (Paired-cell Overlapping Loops of Cards with Authorization), which is a method of controlling the flow of jobs through a production process, and Q-ROC (Quick Response Order Control), which is a system of managing orders that allows companies to quickly respond to changes in demand.<br><br>

												However, QRM techniques are not without limitations. Research by Caggiano et al. (2018) suggests that QRM may not be effective in environments with high variability and low volumes. Additionally, implementing QRM can be complex and costly, requiring significant changes to a company's production processes.<br><br>

												<b>References:</b><br>

												Caggiano, L., Caricato, P., & Mossa, G. (2018). A comparative analysis of lean, agile, and lean-agile supply chain management approaches in the context of SMEs. Journal of Manufacturing Technology Management, 29(5), 876-901.<br>

												Suri, R. (1998). Quick response manufacturing: A companywide approach to reducing lead times. Industrial Press.<br>
											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3> Week 9</h3>
											</header>
											<p>
												This text discusses the importance of creating business continuity (BC) and disaster recovery (DR) plans, as well as the main determining factors in such plans. The main factors include Business Impact Assessments (BIA), Recovery Time Objectives (RTOs), and Recovery Point Objectives (RPOs). Additionally, the text highlights some emerging trends in Information Risk Management. <br><br>

												According to Wang and Liu (2016), business continuity and disaster recovery plans are essential for organizations to ensure uninterrupted business operations. These plans should be based on a thorough understanding of the organization’s business processes and potential risks. <br><br>

												The Business Impact Assessment (BIA) is a critical component of BC/DR planning. It helps identify the critical business processes and systems, and their interdependencies, and assesses the potential impact of disruptions to these processes and systems. (Gordon, 2013).<br><br>

												Recovery Time Objective (RTO) is another key factor in BC/DR planning. It refers to the maximum time allowed for the recovery of critical business processes and systems. (Gordon, 2013).<br><br>

												Recovery Point Objective (RPO) is a measure of how much data an organization can afford to lose in case of a disruption. It determines the frequency of data backups and the maximum tolerable data loss. (Gordon, 2013). <br><br>

												Finally, the text mentions some emerging trends in Information Risk Management, such as Artificial Intelligence (AI) and Machine Learning (ML), Cloud Computing, and Internet of Things (IoT). These trends pose new challenges and require organizations to update their risk management strategies accordingly. (Alam et al., 2018).<br><br>

												<b>References:</b><br>

												Alam, M., Reaz, M., & Islam, M. (2018). Emerging trends in information risk management. International Journal of Computer Science and Network Security, 18(1), 9-19.<br>

												Gordon, L. A., Loeb, M. P., & Lucyshyn, W. (2013). Managing cyber security resources: A cost-benefit analysis. Journal of Computer Security, 21(4), 533-554.<br>

												Wang, H., & Liu, K. (2016). Business continuity and disaster recovery planning: The basics. Journal of Business Continuity & Emergency Planning, 9(1), 23-36.<br>
											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Week 10</h3>
											</header>
											<p>
												The Recovery Point Objective (RPO) and Recovery Time Objective (RTO) are critical factors for Disaster Recovery (DR) solutions. RPO determines the amount of data loss a business can tolerate in a disaster scenario, while RTO defines the maximum tolerable downtime. The appropriate RPO and RTO values for DR solutions depend on various factors, such as business requirements, budget, and complexity. <br><br>

												Several typical system solutions are available to meet standby requirements, such as hot standby, warm standby, and cold standby. A hot standby system provides continuous data replication and immediate failover in case of a disaster. A warm standby system has near-real-time data replication and requires manual intervention to failover. A cold standby system involves a backup system that is only activated in case of a disaster.<br><br>

												<b>References:</b><br>

												Brown, A. (2019). Understanding RPO and RTO. Druva. Retrieved from https://www.druva.com/blog/understanding-rpo-and-rto/<br>
											</p>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Week 11</h3>
											</header>
											<p>
												I have put together a subsequent report to the one delivered on Unit/Week 6 as per requirements of the assignment. Below is the link the full report as an artefact evidence.<br><br>

											</p>
											<ul class="actions">
												<li><a href="https://lucasrbennion.github.io/SRM_PCOM7E_November_2023/pdf/IndividualProjectExecutiveSummary.pdf" class="button">Individual Project Executive Summary</a></li>
											</ul>
										</div>
									</div>
								</section>
								<section>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3> Week 12</h3>
											</header>
											<p>The content display in this GitHub page is the evidence of my e-Portfolio Submission<br><br></p>
											<ul class="actions">
												<li><a href="index.html" class="button">Evidence of e-Portfolio Submission</a></li>
											</ul>
										</div>
									</div>
								</section>
							</section>

						<!-- Three -->
							<section id="three">
								<div class="inner">
									<header class="major">
										<h2>Final Reflections</h2>
									</header>
									<p>
										As I reflect on the Security and Risk Management module, I realise how important it is to consider all possible risks and vulnerabilities while designing and developing a product or carrying out a security review. The module helped me understand the significance of incorporating security measures right from the initial stages of development. I also learned various techniques and tools to identify risks and vulnerabilities and mitigate them effectively.<br><br>

										As a member of my allocated group, I contributed to team activities by identifying potential security threats and suggesting measures to mitigate them. I also ensured that all team members were aware of the best practices and guidelines for secure development.<br><br>

										Being a part of a group has been a great learning experience for me. I have learned how to further collaborate with team members effectively, communicate ideas clearly, and work towards achieving common goals. It has also helped me develop my problem-solving skills and taught me how to think critically while making important decisions.<br><br>

										Overall, the Security and Risk Management module and my experience as a member of a development team have had a positive impact on my personal and professional development. I now have a better understanding of the importance of applying Risk Management techniques as part of my job and feel more confident in my ability to contribute even further to Risk Management discussions in my organisation.
									</p>
									<ul class="actions">
										<li><a href="generic.html" class="button next">Get Started</a></li>
									</ul>
								</div>
							</section>

					</div>

				<!-- Contact -->
					<section id="contact">
						<div class="inner">
							<section>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<label for="name">Name</label>
											<input type="text" name="name" id="name" />
										</div>
										<div class="field half">
											<label for="email">Email</label>
											<input type="text" name="email" id="email" />
										</div>
										<div class="field">
											<label for="message">Message</label>
											<textarea name="message" id="message" rows="6"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send Message" class="primary" /></li>
										<li><input type="reset" value="Clear" /></li>
									</ul>
								</form>
							</section>
							<section class="split">
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-envelope"></span>
										<h3>Email</h3>
										<a href="#">lucasrbennion@gmail.com</a>
									</div>
								</section>
							</section>
						</div>
					</section>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<ul class="icons">
								<li><a href="#" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
								<li><a href="#" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li>
								<li><a href="#" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
								<li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								<li><a href="#" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
							</ul>
							<ul class="copyright">
								<li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>